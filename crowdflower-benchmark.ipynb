{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data from files \n",
    "train = pd.read_csv(\"train.csv\").fillna(\"\")\n",
    "test  = pd.read_csv(\"test.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the training and test date a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>Accent Pillow with Heart Design - Red/Black</td>\n",
       "      <td>Red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n",
       "      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n",
       "      <td>Like a silent and sturdy tree, the Southern En...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n",
       "      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "2   4                  projector   \n",
       "3   5                  wine rack   \n",
       "4   7                 light bulb   \n",
       "\n",
       "                                       product_title  \\\n",
       "0        Accent Pillow with Heart Design - Red/Black   \n",
       "1  Set of 10 Battery Operated Multi LED Train Chr...   \n",
       "2         ViewSonic Pro8200 DLP Multimedia Projector   \n",
       "3  Concept Housewares WR-44526 Solid-Wood Ceiling...   \n",
       "4  Wintergreen Lighting Christmas LED Light Bulb ...   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  Red satin accent pillow embroidered with a hea...                 1   \n",
       "1  Set of 10 Battery Operated Train Christmas Lig...                 4   \n",
       "2                                                                    4   \n",
       "3  Like a silent and sturdy tree, the Southern En...                 4   \n",
       "4  WTGR1011\\nFeatures\\nNickel base, 60,000 averag...                 2   \n",
       "\n",
       "   relevance_variance  \n",
       "0               0.000  \n",
       "1               0.000  \n",
       "2               0.471  \n",
       "3               0.000  \n",
       "4               0.471  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>electric griddle</td>\n",
       "      <td>Star-Max 48 in Electric Griddle</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>phillips coffee maker</td>\n",
       "      <td>Philips SENSEO HD7810 WHITE Single Serve Pod C...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>san francisco 49ers</td>\n",
       "      <td>2013 San Francisco 49ers Clock</td>\n",
       "      <td>A 2013 San Francisco 49ers clock is the ultima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>aveeno shampoo</td>\n",
       "      <td>AVEENO       10.5FLOZ NRSH SHINE SH</td>\n",
       "      <td>Water, Ammonium Lauryl Sulfate, Dimethicone, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>flea and tick control for dogs</td>\n",
       "      <td>Merial Frontline Plus Flea and Tick Control fo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           query  \\\n",
       "0   3                electric griddle   \n",
       "1   6           phillips coffee maker   \n",
       "2   9             san francisco 49ers   \n",
       "3  11                  aveeno shampoo   \n",
       "4  12  flea and tick control for dogs   \n",
       "\n",
       "                                       product_title  \\\n",
       "0                    Star-Max 48 in Electric Griddle   \n",
       "1  Philips SENSEO HD7810 WHITE Single Serve Pod C...   \n",
       "2                     2013 San Francisco 49ers Clock   \n",
       "3                AVEENO       10.5FLOZ NRSH SHINE SH   \n",
       "4  Merial Frontline Plus Flea and Tick Control fo...   \n",
       "\n",
       "                                 product_description  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  A 2013 San Francisco 49ers clock is the ultima...  \n",
       "3  Water, Ammonium Lauryl Sulfate, Dimethicone, S...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My data scrubbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a copy of the data set to scrub\n",
    "jfaTrain = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrub HTML\n",
    "Via BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()  # Download text data sets, including stop words\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def description_to_words( raw_description ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    description_text = BeautifulSoup(raw_description).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", description_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data scrubbing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Description\n",
      "====================\n",
      "Keep your MacBook Air looking clean and pristine with the MacAlly 13\" MacBook Air Case. This lightweight, durable case features a 2-piece snap-on design to protect your MacBook Air from dings and scratches. It offers a custom fit while still providing access to all ports, sensors and vent openings to reduce heat build-up. This state-of-the-art 13\" MacBook Case includes anti-slip silica gel feet and is designed specifically for 13\" models only. It allows you to transport your computer without worry.\n",
      "\n",
      "\n",
      "Cleaned Description\n",
      "===================\n",
      "keep macbook air looking clean pristine macally macbook air case lightweight durable case features piece snap design protect macbook air dings scratches offers custom fit still providing access ports sensors vent openings reduce heat build state art macbook case includes anti slip silica gel feet designed specifically models allows transport computer without worry\n"
     ]
    }
   ],
   "source": [
    "clean_description = review_to_words( train[\"product_description\"][45] )\n",
    "print \"Original Description\"\n",
    "print \"====================\"\n",
    "print train[\"product_description\"][45]\n",
    "print\n",
    "print\n",
    "print \"Cleaned Description\"\n",
    "print \"===================\"\n",
    "print clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply data scrubbing function to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description 1000 of 10158\n",
      "\n",
      "Description 2000 of 10158\n",
      "\n",
      "Description 3000 of 10158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65497012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65516012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Description 4000 of 10158\n",
      "\n",
      "Description 5000 of 10158\n",
      "\n",
      "Description 6000 of 10158\n",
      "\n",
      "Description 7000 of 10158\n",
      "\n",
      "Description 8000 of 10158\n",
      "\n",
      "Description 9000 of 10158\n",
      "\n",
      "Description 10000 of 10158\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/bs4/__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/6552101\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "num_descriptions         = train[\"product_description\"].size\n",
    "clean_train_descriptions = []\n",
    "for i in xrange( 0, num_descriptions ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Description %d of %d\\n\" % ( i+1, num_descriptions )                                                                    \n",
    "    clean_train_descriptions.append( description_to_words_to_words( train[\"product_description\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 1000 of 10158\n",
      "\n",
      "Title 2000 of 10158\n",
      "\n",
      "Title 3000 of 10158\n",
      "\n",
      "Title 4000 of 10158\n",
      "\n",
      "Title 5000 of 10158\n",
      "\n",
      "Title 6000 of 10158\n",
      "\n",
      "Title 7000 of 10158\n",
      "\n",
      "Title 8000 of 10158\n",
      "\n",
      "Title 9000 of 10158\n",
      "\n",
      "Title 10000 of 10158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_titles         = train[\"product_title\"].size\n",
    "clean_train_titles = []\n",
    "for i in xrange( 0, num_titles ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Title %d of %d\\n\" % ( i+1, num_titles )                                                                    \n",
    "    clean_train_titles.append( description_to_words( train[\"product_title\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description 1000 of 10158...\n",
      "Description 2000 of 10158...\n",
      "Description 3000 of 10158...\n",
      "Description 4000 of 10158...\n",
      "Description 5000 of 10158...\n",
      "Description 6000 of 10158...\n",
      "Description 7000 of 10158...\n",
      "Description 8000 of 10158...\n",
      "Description 9000 of 10158...\n",
      "Description 10000 of 10158...\n"
     ]
    }
   ],
   "source": [
    "num_queries         = train[\"query\"].size\n",
    "clean_train_queries = []\n",
    "for i in xrange( 0, num_queries ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Description %d of %d...\" % ( i+1, num_queries )                                                                    \n",
    "    clean_train_queries.append( description_to_words( train[\"query\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"product_description\"] = clean_train_descriptions\n",
    "train[\"product_title\"]       = clean_train_titles\n",
    "train[\"query\"]               = clean_train_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature mapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureMapper:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for feature_name, column_name, extractor in self.features:\n",
    "            extractor.fit(X[column_name], y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        extracted = []\n",
    "        for feature_name, column_name, extractor in self.features:\n",
    "            fea = extractor.transform(X[column_name])\n",
    "            if hasattr(fea, \"toarray\"):\n",
    "                extracted.append(fea.toarray())\n",
    "            else:\n",
    "                extracted.append(fea)\n",
    "        if len(extracted) > 1:\n",
    "            return np.concatenate(extracted, axis=1)\n",
    "        else: \n",
    "            return extracted[0]\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        extracted = []\n",
    "        for feature_name, column_name, extractor in self.features:\n",
    "            fea = extractor.fit_transform(X[column_name], y)\n",
    "            if hasattr(fea, \"toarray\"):\n",
    "                extracted.append(fea.toarray())\n",
    "            else:\n",
    "                extracted.append(fea)\n",
    "        if len(extracted) > 1:\n",
    "            return np.concatenate(extracted, axis=1)\n",
    "        else: \n",
    "            return extracted[0]\n",
    "\n",
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-84-4b1844b9838b>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-4b1844b9838b>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class SimpleTransform(BaseEstimator):\n",
    "    def __init__(self, transformer=identity):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.array([self.transformer(x) for x in X], ndmin=2).T\n",
    "\n",
    "#                          Feature Set Name            Data Frame Column              Transformer\n",
    "features = FeatureMapper([('QueryBagOfWords',          'query',                       CountVectorizer(max_features=200)),\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate FeatureMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                          Feature Set Name            Data Frame Column              Transformer\n",
    "features = FeatureMapper([('QueryBagOfWords',          'query',                       CountVectorizer(max_features=200)),\n",
    "                          ('TitleBagOfWords',          'product_title',               CountVectorizer(max_features=200)),\n",
    "                          ('DescriptionBagOfWords',    'product_description',         CountVectorizer(max_features=200)),\n",
    "                          ('QueryTokensInTitle',       'query_tokens_in_title',       SimpleTransform()),\n",
    "                          ('QueryTokensInDescription', 'query_tokens_in_description', SimpleTransform())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = train\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "data[\"query_tokens_in_title\"] = 0.0\n",
    "data[\"query_tokens_in_description\"] = 0.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = data.loc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query       = set(x.lower() for x in token_pattern.findall(row[\"query\"]))\n",
    "title       = set(x.lower() for x in token_pattern.findall(row[\"product_title\"]))\n",
    "description = set(x.lower() for x in token_pattern.findall(row[\"product_description\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n",
      "0\n",
      "3\n",
      "10\n",
      "0.3\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "len(query.intersection(title)) / len(title)\n",
    "\n",
    "foo = len(query.intersection(title))\n",
    "bar = len(title)\n",
    "\n",
    "print foo\n",
    "print bar\n",
    "print foo / bar\n",
    "\n",
    "foo = 3\n",
    "bar = 10\n",
    "\n",
    "print foo\n",
    "print bar\n",
    "print float(foo) / float(bar)\n",
    "print float(foo/bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    data[\"query_tokens_in_title\"] = 0.0\n",
    "    data[\"query_tokens_in_description\"] = 0.0\n",
    "    for i, row in data.iterrows():\n",
    "        query       = set(x.lower() for x in token_pattern.findall(row[\"query\"]))\n",
    "        title       = set(x.lower() for x in token_pattern.findall(row[\"product_title\"]))\n",
    "        description = set(x.lower() for x in token_pattern.findall(row[\"product_description\"]))\n",
    "        if len(title) > 0:\n",
    "            data.set_value(i, \"query_tokens_in_title\", float(len(query.intersection(title)))/float(len(title)))\n",
    "        if len(description) > 0:\n",
    "            data.set_value(i, \"query_tokens_in_description\", float(len(query.intersection(description)))/float(len(description)))\n",
    "\n",
    "extract_features(train)\n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "      <th>query_tokens_in_title</th>\n",
       "      <th>query_tokens_in_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>accent pillow heart design red black</td>\n",
       "      <td>red satin accent pillow embroidered heart blac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>set battery operated multi led train christmas...</td>\n",
       "      <td>set battery operated train christmas lights it...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>viewsonic pro dlp multimedia projector</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>concept housewares wr solid wood ceiling wall ...</td>\n",
       "      <td>like silent sturdy tree southern enterprises b...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>wintergreen lighting christmas led light bulb ...</td>\n",
       "      <td>wtgr features nickel base average hours acryli...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  \\\n",
       "0   1  bridal shower decorations   \n",
       "1   2       led christmas lights   \n",
       "2   4                  projector   \n",
       "3   5                  wine rack   \n",
       "4   7                 light bulb   \n",
       "\n",
       "                                       product_title  \\\n",
       "0               accent pillow heart design red black   \n",
       "1  set battery operated multi led train christmas...   \n",
       "2             viewsonic pro dlp multimedia projector   \n",
       "3  concept housewares wr solid wood ceiling wall ...   \n",
       "4  wintergreen lighting christmas led light bulb ...   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  red satin accent pillow embroidered heart blac...                 1   \n",
       "1  set battery operated train christmas lights it...                 4   \n",
       "2                                                                    4   \n",
       "3  like silent sturdy tree southern enterprises b...                 4   \n",
       "4  wtgr features nickel base average hours acryli...                 2   \n",
       "\n",
       "   relevance_variance  query_tokens_in_title  query_tokens_in_description  \n",
       "0               0.000               0.000000                     0.000000  \n",
       "1               0.000               0.300000                     0.037037  \n",
       "2               0.471               0.200000                     0.000000  \n",
       "3               0.000               0.153846                     0.016949  \n",
       "4               0.471               0.285714                     0.062500  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass into Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"extract_features\", features),\n",
    "                     (\"classify\", RandomForestClassifier(n_estimators=200,\n",
    "                                                         n_jobs=1,\n",
    "                                                         min_samples_split=2,\n",
    "                                                         random_state=1))])\n",
    "\n",
    "pipeline.fit(train, train[\"median_relevance\"])\n",
    "\n",
    "predictions = pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test[\"id\"], \"prediction\": predictions})\n",
    "submission.to_csv(\"python_benchmark.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CROSS-VALIDATION script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "\n",
    "# Kappa Scorer \n",
    "kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?cross_validation.StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-af12f9cb66b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jason/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, indices, shuffle, random_state)\u001b[0m\n\u001b[1;32m    400\u001b[0m                  random_state=None):\n\u001b[1;32m    401\u001b[0m         super(StratifiedKFold, self).__init__(\n\u001b[0;32m--> 402\u001b[0;31m             len(y), n_folds, indices, shuffle, random_state)\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "cv = cross_validation.StratifiedKFold(len(train), n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?cross_validation.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-f17e1ea60c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jason/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, score_func, pre_dispatch)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                         allow_nans=True, allow_nd=True)\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jason/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_check_cv\u001b[0;34m(cv, X, y, classifier, warn_mask)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mneeds_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneeds_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jason/anaconda/lib/python2.7/site-packages/sklearn/utils/multiclass.pyc\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 284\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_sequence_of_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got None"
     ]
    }
   ],
   "source": [
    "cross_validation.cross_val_score(pipeline, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10158, 8)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22513, 6)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-6323166a2d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'size' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
